{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Christine Plumejeaud-Perreau, UMR MIGRINTER 7301\n",
    "\n",
    "02 may 2022\n",
    "projet ANR PORTIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des données de raw_flows pour regroupement par destination et analyse des produits et tonnages expédiés\n",
    "# Analyse sur 1787 et France entière. \n",
    "\n",
    "Note 1787 : Oui, on a les données de Bayonne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.core.frame as pf\n",
    "\n",
    "import json, urllib\n",
    "import plotly as py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10081, 17)\n",
      "Unnamed: 0                                 int64\n",
      "departure_uhgs_id                         object\n",
      "departure_fr                              object\n",
      "destination_uhgs_id                       object\n",
      "destination_fr                            object\n",
      "destination_partner_balance_1789          object\n",
      "destination_partner_balance_supp_1789     object\n",
      "destination_substate_1789_fr              object\n",
      "destination_state_1789_fr                 object\n",
      "tonnage                                  float64\n",
      "outdate_fixed                             object\n",
      "commodity_purpose                         object\n",
      "commodity_purpose2                        object\n",
      "commodity_purpose3                        object\n",
      "commodity_purpose4                        object\n",
      "all_cargos                                object\n",
      "nb_cargo                                 float64\n",
      "dtype: object\n",
      "Index(['Unnamed: 0', 'departure_uhgs_id', 'departure_fr',\n",
      "       'destination_uhgs_id', 'destination_fr',\n",
      "       'destination_partner_balance_1789',\n",
      "       'destination_partner_balance_supp_1789', 'destination_substate_1789_fr',\n",
      "       'destination_state_1789_fr', 'tonnage', 'outdate_fixed',\n",
      "       'commodity_purpose', 'commodity_purpose2', 'commodity_purpose3',\n",
      "       'commodity_purpose4', 'all_cargos', 'nb_cargo'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" 'Unnamed: 0', 'departure_uhgs_id', 'departure_fr',\\n       'destination_uhgs_id', 'destination_fr',\\n       'destination_partner_balance_supp_1789', 'destination_substate_1789_fr',\\n       'destination_state_1789_fr', 'tonnage', 'outdate_fixed',\\n       'commodity_purpose', 'commodity_purpose2', 'commodity_purpose3',\\n       'commodity_purpose4', 'all_cargos', 'nb_cargo' \""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "type(raw_flows) #list\n",
    "\n",
    "print(raw_flows.shape) #(30722, 17)\n",
    "print(raw_flows.dtypes)# Récupérer les raw_flows\n",
    "#http://data.portic.fr/api/rawflows/?format=csv&date=1787&params=departure_uhgs_id,departure_fr,destination_uhgs_id,destination_fr,destination_partner_balance_1789,destination_partner_balance_supp_1789,destination_substate_1789_fr,destination_state_1789_fr,tonnage,outdate_fixed,commodity_purpose,commodity_purpose2,commodity_purpose3,commodity_purpose4,all_cargos,nb_cargo\n",
    "\n",
    "#curl -o ./raw_flows_1789.csv \"data.portic.fr/api/rawflows/?format=csv&date=1789&params=departure_uhgs_id,departure_fr,destination_uhgs_id,destination_fr,destination_partner_balance_1789,destination_partner_balance_supp_1789,destination_substate_1789_fr,destination_state_1789_fr,tonnage,outdate_fixed,commodity_purpose,commodity_purpose2,commodity_purpose3,commodity_purpose4,all_cargos,nb_cargo\"\n",
    "raw_flows = pd.read_csv(\"./raw_flows_1787.csv\", encoding='utf8', sep=',')\n",
    "\n",
    "\n",
    "print(raw_flows.columns)\n",
    "\n",
    "''' 'Unnamed: 0', 'departure_uhgs_id', 'departure_fr',\n",
    "       'destination_uhgs_id', 'destination_fr',\n",
    "       'destination_partner_balance_supp_1789', 'destination_substate_1789_fr',\n",
    "       'destination_state_1789_fr', 'tonnage', 'outdate_fixed',\n",
    "       'commodity_purpose', 'commodity_purpose2', 'commodity_purpose3',\n",
    "       'commodity_purpose4', 'all_cargos', 'nb_cargo' '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    'departure_uhgs_id', 'departure_fr',\n",
    "       'destination_uhgs_id', 'destination_fr', 'destination_substate_1789_fr',\n",
    "       'destination_state_1789_fr', 'tonnage', 'outdate_fixed',\n",
    "       'commodity_purpose', 'commodity_purpose2', 'commodity_purpose3',\n",
    "       'commodity_purpose4', 'all_cargos', 'nbproduits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7836, 17)\n",
      "Index(['Unnamed: 0', 'departure_uhgs_id', 'departure_fr',\n",
      "       'destination_uhgs_id', 'destination_fr',\n",
      "       'destination_partner_balance_1789',\n",
      "       'destination_partner_balance_supp_1789', 'destination_substate_1789_fr',\n",
      "       'destination_state_1789_fr', 'tonnage', 'outdate_fixed',\n",
      "       'commodity_purpose', 'commodity_purpose2', 'commodity_purpose3',\n",
      "       'commodity_purpose4', 'all_cargos', 'nb_cargo'],\n",
      "      dtype='object')\n",
      "Index(['departure_uhgs_id', 'departure_fr', 'destination_uhgs_id',\n",
      "       'destination_fr', 'destination_partner_balance_1789',\n",
      "       'destination_partner_balance_supp_1789', 'destination_substate_1789_fr',\n",
      "       'destination_state_1789_fr', 'tonnage', 'outdate_fixed',\n",
      "       'commodity_purpose', 'commodity_purpose2', 'commodity_purpose3',\n",
      "       'commodity_purpose4', 'all_cargos', 'nb_cargo'],\n",
      "      dtype='object')\n",
      "(7836, 16)\n",
      "(7836, 16)\n"
     ]
    }
   ],
   "source": [
    "# Filtrer : oui, la pêche et le lest et ce qui part vers la France \n",
    "# Mais tagger les valeurs expédiées en GB particulièrement ? Oui. \n",
    "\n",
    "# dunkerque = raw_flows.query('departure_fr==\"Dunkerque\"')\n",
    "# print(dunkerque.shape)\n",
    "france = raw_flows.query('destination_partner_balance_supp_1789==\"Etranger\"') #Pas la France\n",
    "france = france.query('destination_uhgs_id!=\"C0000009\"') #Afrique\n",
    "france = france.query('destination_uhgs_id!=\"A0146289\"') #Islande\n",
    "france = france.query('destination_uhgs_id!=\"B0000715\"')  #Terre-Neuve\n",
    "france = france.query('commodity_purpose!=\"Lège\"')  #pas à vide (Lège)\n",
    "france = france.query('commodity_purpose!=\"lest\"')  #pas à vide (lest)\n",
    "france = france.query('commodity_purpose2!=\"lest\"')  #pas à vide (lest)\n",
    "france = france.query('commodity_purpose!=\"pêche\"')  #pas pour la pêche\n",
    "print(france.shape) #(193, 16)\n",
    "\n",
    "\n",
    "print(france.columns)\n",
    "\n",
    "#dunkerque = dunkerque.query('destination_state_1789_fr!=\"Grande-Bretagne\"') #Pas le smogglage vers l'angleterre\n",
    "\n",
    "france = france.drop(['Unnamed: 0'], axis=1) #'all_cargos'\n",
    "print(france.columns)\n",
    "\n",
    "print(france.shape) #(7836, 16)\n",
    "\n",
    "#Il arrive que des cargos soient na \n",
    "\n",
    "values = {\"all_cargos\": '', \"nb_cargo\": 0}\n",
    "france = france.fillna(value=values)\n",
    "#france = france.dropna(subset=['all_cargos'])\n",
    "print(france.shape) #(7836, 16)\n",
    "# GROS trou dans la rquette : 7836 - 4970 disparaissent car porduits non renseignés\n",
    "\n",
    "france.to_csv (r'./flux_france_1787.csv', index = None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premier apercu des destinations d'export de France vers l'étranger, AVEC GB, MAIS hors pêche, hors navires à vide. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   destination_partner_balance_1789  count\n",
      "0                        Angleterre   4244\n",
      "1                          Danemark    429\n",
      "2                           Espagne    654\n",
      "3               Etats de l'Empereur    305\n",
      "4                        Etats-Unis    189\n",
      "5                          Hollande    643\n",
      "6                          Portugal    175\n",
      "7                            Prusse     98\n",
      "8        Quatre villes hanséatiques    348\n",
      "9                            Russie     68\n",
      "10                            Suède    110\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination_partner_balance_1789</th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Angleterre</td>\n",
       "      <td>4088</td>\n",
       "      <td>153070.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Danemark</td>\n",
       "      <td>427</td>\n",
       "      <td>42054.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Espagne</td>\n",
       "      <td>615</td>\n",
       "      <td>46889.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Etats de l'Empereur</td>\n",
       "      <td>304</td>\n",
       "      <td>28720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Etats-Unis</td>\n",
       "      <td>188</td>\n",
       "      <td>32969.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hollande</td>\n",
       "      <td>641</td>\n",
       "      <td>74228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>173</td>\n",
       "      <td>23302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Prusse</td>\n",
       "      <td>98</td>\n",
       "      <td>18268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Quatre villes hanséatiques</td>\n",
       "      <td>348</td>\n",
       "      <td>65575.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Russie</td>\n",
       "      <td>68</td>\n",
       "      <td>14063.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Suède</td>\n",
       "      <td>110</td>\n",
       "      <td>14117.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   destination_partner_balance_1789  count       sum\n",
       "0                        Angleterre   4088  153070.0\n",
       "1                          Danemark    427   42054.0\n",
       "2                           Espagne    615   46889.0\n",
       "3               Etats de l'Empereur    304   28720.0\n",
       "4                        Etats-Unis    188   32969.0\n",
       "5                          Hollande    641   74228.0\n",
       "6                          Portugal    173   23302.0\n",
       "7                            Prusse     98   18268.0\n",
       "8        Quatre villes hanséatiques    348   65575.0\n",
       "9                            Russie     68   14063.0\n",
       "10                            Suède    110   14117.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Note, il y a une difference entre size et count, car il y a des navires avec tonnage inconnu\n",
    "gdata = pf.DataFrame({'count' : france.groupby( [ \"destination_partner_balance_1789\"] ).size()}).reset_index()\n",
    "print(gdata)\n",
    "\n",
    "pf.DataFrame(france.groupby([ \"destination_partner_balance_1789\"])['tonnage'].agg(['count','sum'])).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import ast\n",
    "\n",
    "def unstack_cargos_in_pointcalls(df):\n",
    "  by_pointcalls = []\n",
    "\n",
    "  for _, row in df.iterrows():\n",
    "    if row['all_cargos'] != '' and row['all_cargos'] != 'nan':\n",
    "      truc = row['all_cargos']\n",
    "      \n",
    "      #truc = truc.replace(\"'\", '\"').replace(\"None\", 'null')\n",
    "      #.replace(\"bœ\\x9c\\x9cuf\", \"boeuf\")\n",
    "      #print(json.dumps(truc))\n",
    "      #truc = json.dumps(truc)\n",
    "      #print(truc)\n",
    "      #cargos = json.loads(truc)\n",
    "      cargos = ast.literal_eval(truc) #MAGIE\n",
    "      #print(type(cargos))\n",
    "      for cargo in cargos:\n",
    "        if  cargo['commodity_standardized_fr'] != 'Lest' : \n",
    "          if  cargo['commodity_standardized_fr'] != None : \n",
    "            by_pointcalls.append({\n",
    "              \"cargo\": cargo['commodity_purpose'],\n",
    "              \"cargo_standardized_fr\": cargo['commodity_standardized_fr'],\n",
    "              **row\n",
    "            })\n",
    "          else :\n",
    "            by_pointcalls.append({\n",
    "              \"cargo\": cargo['commodity_purpose'],\n",
    "              \"cargo_standardized_fr\": cargo['commodity_purpose'].lower(),\n",
    "              **row\n",
    "            })\n",
    "    else:\n",
    "      by_pointcalls.append({\n",
    "        \"cargo\": \"\",\n",
    "        \"cargo_standardized_fr\": \"\",\n",
    "        **row\n",
    "      })\n",
    "  return by_pointcalls\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USUED CODE FOR THE MOMENT\n",
    "\n",
    "\n",
    "from dunkerquesprint import build_toflit18_classif_multimap, get_online_csv\n",
    "\n",
    "def get_toflit18_classification(product_classification=\"product_simplification\"):\n",
    "    # créer un dict dont chaque clé sera une des classifications à parcourir,\n",
    "  # et chaque valeur un dict dont les clés sont les formes parentes et les valeurs les formes enfant\n",
    "  classification_path, classif_multi_dict = build_toflit18_classif_multimap(product_classification)\n",
    "  prev_classif = 'product_source'\n",
    "  for classif in classification_path:\n",
    "    classif_multi_dict[classif] = {}\n",
    "    # on créée un dict alternatif avec les valeurs en lowercase pour parer à d'éventuels problèmes liés à la casse\n",
    "    classif_multi_dict[classif + '_lower'] = {}\n",
    "    # récupérer le csv à jour de la classification sur le repo toflit18_data\n",
    "    toflit18_csv_url = 'https://raw.githubusercontent.com/medialab/toflit18_data/master/base/classification_' + classif + '.csv'\n",
    "    # télécharger le csv depuis toflit18_data\n",
    "    classif_data = get_online_csv(toflit18_csv_url)\n",
    "    prev_key = prev_classif.split('product_')[1]\n",
    "    current_key = classif.split('product_')[1]\n",
    "    for row in classif_data:\n",
    "      # nom de la classification \"parent\" : e.g. \"orthographic\"\n",
    "      parent_value = row[prev_key]\n",
    "      # nom de la classification \"enfant\" : e.g. \"simplification\"\n",
    "      child_value = row[current_key]\n",
    "      classif_multi_dict[classif][parent_value] = child_value\n",
    "      # gérer les problèmes de casse en stockant dans le dict alternatif la valeur originale et la valeur en lower\n",
    "      classif_multi_dict[classif + '_lower'][parent_value.lower()] = {\n",
    "        \"original\": child_value,\n",
    "        \"lower\" : child_value.lower()\n",
    "      }\n",
    "    prev_classif = classif\n",
    "\n",
    "  return prev_classif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traduire les produits de navigo en produits de toflit\n",
    "\n",
    "from dunkerquesprint import build_toflit18_classif_multimap\n",
    "product_classification=\"product_simplification\"\n",
    "#product_classification=\"product_RE_aggregate\"\n",
    "\n",
    "#product_classification=\"product_reexportations\"\n",
    "classification_path, classif_multi_dict = build_toflit18_classif_multimap(product_classification)\n",
    "\n",
    "NAN_TOFLIT = \"Unknown for TOFLIT\"\n",
    "\n",
    "def translate_as_toflit_product(source_name):\n",
    "  # créer un dict dont chaque clé sera une des classifications à parcourir,\n",
    "  # et chaque valeur un dict dont les clés sont les formes parentes et les valeurs les formes enfant\n",
    "  \n",
    "  # la valeur PORTIC cargo_standardized_fr correspond au niveau \"source\" des classifications TOFLIT18\n",
    "  #source_name = pointcall[\"cargo_standardized_fr\"]\n",
    "  translated_name = None\n",
    "  if source_name is not None:\n",
    "    # on stocke dans une valeur courante la traduction TOFLIT18 (qui va par exemple correspondre successivement à source -> orthographic -> simplification)\n",
    "    translated_name = source_name\n",
    "    # parcourir les classifs pour trouver la bonne valeur\n",
    "    for classif in classification_path:\n",
    "      # si la valeur est dans le dict de la classif toflit18 courante on le traduit\n",
    "      if translated_name is not None and translated_name in classif_multi_dict[classif]:\n",
    "        translated_name = classif_multi_dict[classif][translated_name]\n",
    "      # si la valeur matche en lowercase on la traduit aussi\n",
    "      elif translated_name is not None and translated_name.lower() in classif_multi_dict[classif + '_lower']:\n",
    "        translated_name = classif_multi_dict[classif + '_lower'][translated_name.lower()][\"original\"]\n",
    "      # si pas de valeur trouvée => alignement impossible, besoin de màj côté toflit18 pour intégrer cette forme\n",
    "      else:\n",
    "        translated_name = NAN_TOFLIT\n",
    "  #pointcall[\"commodity_as_toflit\"] = translated_name\n",
    "  return translated_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cargo', 'cargo_standardized_fr', 'departure_uhgs_id', 'departure_fr',\n",
      "       'destination_uhgs_id', 'destination_fr',\n",
      "       'destination_partner_balance_1789',\n",
      "       'destination_partner_balance_supp_1789', 'destination_substate_1789_fr',\n",
      "       'destination_state_1789_fr', 'tonnage', 'outdate_fixed', 'nb_cargo',\n",
      "       'commodity_as_toflit'],\n",
      "      dtype='object')\n",
      "(9337, 14)\n"
     ]
    }
   ],
   "source": [
    "by_pointcalls =  unstack_cargos_in_pointcalls(france)\n",
    "export_france_1787 = pd.DataFrame(by_pointcalls, columns=['cargo', 'cargo_standardized_fr']+france.columns.tolist())\n",
    "\n",
    "#print(export_france_1787.columns)\n",
    "\n",
    "export_france_1787['commodity_as_toflit'] = export_france_1787['cargo_standardized_fr'].apply(translate_as_toflit_product)\n",
    "\n",
    "export_france_1787 = export_france_1787.drop(['commodity_purpose', 'commodity_purpose2', 'commodity_purpose3', 'commodity_purpose4', 'all_cargos'], axis=1)\n",
    "\n",
    "print(export_france_1787.columns)\n",
    "print(export_france_1787.shape) #(9337, 14)\n",
    "export_france_1787.to_csv (r'./export_france_1787.csv', index = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cplume01\\AppData\\Local\\Temp\\ipykernel_15796\\1177664358.py:13: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  exports = pd.DataFrame(export_france_1787.groupby([ \"destination_partner_balance_1789\",\"commodity_as_toflit\"])['tonnage','tonnage_per_product'].agg(['count', 'sum'])).reset_index()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas.core.frame as pf\n",
    "\n",
    "# Lire le fichier \n",
    "#export_france_1787 = pd.read_csv(\"./export_france_1787.csv\")\n",
    "export_france_1787['tonnage_per_product'] = export_france_1787['tonnage'] / export_france_1787['nb_cargo']\n",
    "\n",
    "gdata = pf.DataFrame({'count' : export_france_1787.groupby( [ \"destination_partner_balance_1789\",\"commodity_as_toflit\"] ).size()}).reset_index()\n",
    "#print(gdata)\n",
    "\n",
    "pd.DataFrame(export_france_1787.groupby([ \"destination_partner_balance_1789\",\"commodity_as_toflit\"])['tonnage'].agg(['sum','count', 'mean'])).reset_index()\n",
    "\n",
    "exports = pd.DataFrame(export_france_1787.groupby([ \"destination_partner_balance_1789\",\"commodity_as_toflit\"])['tonnage','tonnage_per_product'].agg(['count', 'sum'])).reset_index()\n",
    "exports.set_axis(['destination_partner_balance_1789', 'commodity_as_toflit', 'nb_ships', 'sum_tonnage', 'nb_ships2', 'sum_tonnage_per_product'], axis=1, inplace=True)\n",
    "exports.to_csv (r'./export_france_1787_par_pays_par_produits.csv', index = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pour 1789, on s'intéresse à la même chose pour Dunkerque, La Rochelle et Marseille\n",
    "# ie la navigation pour l'étranger sans navires à vide, sans pêche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'departure_uhgs_id', 'departure_fr',\n",
      "       'destination_uhgs_id', 'destination_fr',\n",
      "       'destination_partner_balance_1789',\n",
      "       'destination_partner_balance_supp_1789', 'destination_substate_1789_fr',\n",
      "       'destination_state_1789_fr', 'tonnage', 'outdate_fixed',\n",
      "       'commodity_purpose', 'commodity_purpose2', 'commodity_purpose3',\n",
      "       'commodity_purpose4', 'all_cargos', 'nb_cargo'],\n",
      "      dtype='object')\n",
      "(1239, 17)\n",
      "(1239, 16)\n",
      "Index(['cargo', 'cargo_standardized_fr', 'departure_uhgs_id', 'departure_fr',\n",
      "       'destination_uhgs_id', 'destination_fr',\n",
      "       'destination_partner_balance_1789',\n",
      "       'destination_partner_balance_supp_1789', 'destination_substate_1789_fr',\n",
      "       'destination_state_1789_fr', 'tonnage', 'outdate_fixed', 'nb_cargo',\n",
      "       'commodity_as_toflit'],\n",
      "      dtype='object')\n",
      "(2192, 14)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#http://data.portic.fr/api/rawflows/?format=csv&date=1789&params=departure_uhgs_id,departure_fr,destination_uhgs_id,destination_fr,destination_partner_balance_1789,destination_partner_balance_supp_1789,destination_substate_1789_fr,destination_state_1789_fr,tonnage,outdate_fixed,commodity_purpose,commodity_purpose2,commodity_purpose3,commodity_purpose4,all_cargos,nb_cargo\n",
    "\n",
    "#curl -o ./raw_flows_1789.csv \"data.portic.fr/api/rawflows/?format=csv&date=1789&params=departure_uhgs_id,departure_fr,destination_uhgs_id,destination_fr,destination_partner_balance_1789,destination_partner_balance_supp_1789,destination_substate_1789_fr,destination_state_1789_fr,tonnage,outdate_fixed,commodity_purpose,commodity_purpose2,commodity_purpose3,commodity_purpose4,all_cargos,nb_cargo\"\n",
    "raw_flows = pd.read_csv(\"./raw_flows_1789.csv\", encoding='utf8', sep=',')\n",
    "\n",
    "\n",
    "print(raw_flows.columns)\n",
    "\n",
    "#Filtrer : oui, la pêche et le lest et ce qui part vers la France \n",
    "# Mais tagger les valeurs expédiées en GB particulièrement ? Oui. \n",
    "\n",
    "dunkerque = raw_flows.query('departure_fr==\"Dunkerque\"')\n",
    "# print(dunkerque.shape)\n",
    "dunkerque = dunkerque.query('destination_partner_balance_supp_1789==\"Etranger\"') #Pas la France\n",
    "dunkerque = dunkerque.query('destination_uhgs_id!=\"C0000009\"') #Afrique\n",
    "dunkerque = dunkerque.query('destination_uhgs_id!=\"A0146289\"') #Islande\n",
    "dunkerque = dunkerque.query('destination_uhgs_id!=\"B0000715\"')  #Terre-Neuve\n",
    "dunkerque = dunkerque.query('commodity_purpose!=\"Lège\"')  #pas à vide (Lège)\n",
    "dunkerque = dunkerque.query('commodity_purpose!=\"lest\"')  #pas à vide (lest)\n",
    "dunkerque = dunkerque.query('commodity_purpose2!=\"lest\"')  #pas à vide (lest)\n",
    "dunkerque = dunkerque.query('commodity_purpose!=\"pêche\"')  #pas pour la pêche\n",
    "print(dunkerque.shape) #(1239, 17)\n",
    "\n",
    "\n",
    "#print(dunkerque.columns)\n",
    "\n",
    "#dunkerque = dunkerque.query('destination_state_1789_fr!=\"Grande-Bretagne\"') #Pas le smogglage vers l'angleterre\n",
    "\n",
    "dunkerque = dunkerque.drop(['Unnamed: 0'], axis=1) #'all_cargos'\n",
    "print(dunkerque.shape) #(1239, 16)\n",
    "\n",
    "#Il arrive que des cargos soient na \n",
    "\n",
    "produits_connus = dunkerque.dropna(subset=['all_cargos'])\n",
    "#print(produits_connus.shape) #(1239, 16)\n",
    "\n",
    "values = {\"all_cargos\": '', \"nb_cargo\": 0}\n",
    "dunkerque = dunkerque.fillna(value=values)\n",
    "\n",
    "\n",
    "## Maintenant on duplique les lignes : une par produit, et on aligne avec les produits de Toflit'18\n",
    "\n",
    "by_pointcalls =  unstack_cargos_in_pointcalls(dunkerque)\n",
    "export_dunkerque_1789 = pd.DataFrame(by_pointcalls, columns=['cargo', 'cargo_standardized_fr']+dunkerque.columns.tolist())\n",
    "\n",
    "#print(export_dunkerque_1789.columns)\n",
    "\n",
    "export_dunkerque_1789['commodity_as_toflit'] = export_dunkerque_1789['cargo_standardized_fr'].apply(translate_as_toflit_product)\n",
    "export_dunkerque_1789 = export_dunkerque_1789.drop(['commodity_purpose', 'commodity_purpose2', 'commodity_purpose3', 'commodity_purpose4', 'all_cargos'], axis=1)\n",
    "\n",
    "print(export_dunkerque_1789.columns)\n",
    "print(export_dunkerque_1789.shape) #(2192, 14)\n",
    "\n",
    "export_dunkerque_1789.to_csv (r'./suite_flux_dunkerque_1789.csv', index = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regroupement par produit et par partenaire toflit des exports de Dunkerque en 1789\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   destination_partner_balance_1789 commodity_as_toflit  count\n",
      "0                        Angleterre  Unknown for TOFLIT     11\n",
      "1                        Angleterre              [vide]      1\n",
      "2                        Angleterre             batiste      1\n",
      "3                        Angleterre    bois de Campêche      1\n",
      "4                        Angleterre             briques      1\n",
      "..                              ...                 ...    ...\n",
      "86       Quatre villes hanséatiques        marchandises      1\n",
      "87       Quatre villes hanséatiques               tabac      3\n",
      "88       Quatre villes hanséatiques                 vin      1\n",
      "89                            Suède  Unknown for TOFLIT      1\n",
      "90                            Suède            genièvre      1\n",
      "\n",
      "[91 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cplume01\\AppData\\Local\\Temp\\ipykernel_15796\\2232765458.py:13: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  exports = pd.DataFrame(export_dunkerque_1789.groupby([ \"destination_partner_balance_1789\",\"commodity_as_toflit\"])['tonnage','tonnage_per_product'].agg(['count', 'sum'])).reset_index()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas.core.frame as pf\n",
    "\n",
    "# Lire le fichier \n",
    "#export_dunkerque_1789 = pd.read_csv(\"./suite_flux_dunkerque_1789.csv\")\n",
    "export_dunkerque_1789['tonnage_per_product'] = export_dunkerque_1789['tonnage'] / export_dunkerque_1789['nb_cargo']\n",
    "\n",
    "gdata = pf.DataFrame({'count' : export_dunkerque_1789.groupby( [ \"destination_partner_balance_1789\",\"commodity_as_toflit\"] ).size()}).reset_index()\n",
    "print(gdata)\n",
    "\n",
    "pd.DataFrame(export_dunkerque_1789.groupby([ \"destination_partner_balance_1789\",\"commodity_as_toflit\"])['tonnage'].agg(['sum','count', 'mean'])).reset_index()\n",
    "\n",
    "exports = pd.DataFrame(export_dunkerque_1789.groupby([ \"destination_partner_balance_1789\",\"commodity_as_toflit\"])['tonnage','tonnage_per_product'].agg(['count', 'sum'])).reset_index()\n",
    "exports.set_axis(['destination_partner_balance_1789', 'commodity_as_toflit', 'nb_ships', 'sum_tonnage', 'nb_ships2', 'sum_tonnage_per_product'], axis=1, inplace=True)\n",
    "exports.to_csv (r'./suite_export_dunkerque_1789_par_pays_par_produits.csv', index = None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pour La Rochelle, en 1789\n",
    "\n",
    "Attention, à la Rochelle, on ne connait jamais le produit car non renseigné. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'departure_uhgs_id', 'departure_fr',\n",
      "       'destination_uhgs_id', 'destination_fr',\n",
      "       'destination_partner_balance_1789',\n",
      "       'destination_partner_balance_supp_1789', 'destination_substate_1789_fr',\n",
      "       'destination_state_1789_fr', 'tonnage', 'outdate_fixed',\n",
      "       'commodity_purpose', 'commodity_purpose2', 'commodity_purpose3',\n",
      "       'commodity_purpose4', 'all_cargos', 'nb_cargo'],\n",
      "      dtype='object')\n",
      "(35, 17)\n",
      "(35, 16)\n",
      "Nombre de départs avec produits connus\n",
      "(0, 16)\n",
      "Index(['cargo', 'cargo_standardized_fr', 'departure_uhgs_id', 'departure_fr',\n",
      "       'destination_uhgs_id', 'destination_fr',\n",
      "       'destination_partner_balance_1789',\n",
      "       'destination_partner_balance_supp_1789', 'destination_substate_1789_fr',\n",
      "       'destination_state_1789_fr', 'tonnage', 'outdate_fixed', 'nb_cargo',\n",
      "       'commodity_as_toflit'],\n",
      "      dtype='object')\n",
      "(35, 14)\n"
     ]
    }
   ],
   "source": [
    "# Prendre les données\n",
    "##departure_ferme_bureau, departure_action \n",
    "#departure_ferme_bureau='La Rochelle'\n",
    "#Equivalent à ces ports\n",
    "#    Esnandes\n",
    "#    La Rochelle\n",
    "#    mer des Pertuis\n",
    "\n",
    "#http://data.portic.fr/api/rawflows/?format=csv&date=1789&params=departure_uhgs_id,departure_fr,destination_uhgs_id,destination_fr,destination_partner_balance_1789,destination_partner_balance_supp_1789,destination_substate_1789_fr,destination_state_1789_fr,tonnage,outdate_fixed,commodity_purpose,commodity_purpose2,commodity_purpose3,commodity_purpose4,all_cargos,nb_cargo\n",
    "\n",
    "#curl -o ./raw_flows_1789.csv \"data.portic.fr/api/rawflows/?format=csv&date=1789&params=departure_uhgs_id,departure_fr,destination_uhgs_id,destination_fr,destination_partner_balance_1789,destination_partner_balance_supp_1789,destination_substate_1789_fr,destination_state_1789_fr,tonnage,outdate_fixed,commodity_purpose,commodity_purpose2,commodity_purpose3,commodity_purpose4,all_cargos,nb_cargo\"\n",
    "raw_flows = pd.read_csv(\"./raw_flows_1789.csv\", encoding='utf8', sep=',')\n",
    "\n",
    "\n",
    "print(raw_flows.columns)\n",
    "\n",
    "#Filtrer : oui, la pêche et le lest et ce qui part vers la France \n",
    "# Mais tagger les valeurs expédiées en GB particulièrement ? Oui. \n",
    "\n",
    "lRochelle = raw_flows.query('departure_fr==\"La Rochelle\" or departure_fr==\"Esnandes\" or departure_fr==\"mer des Pertuis\"')\n",
    "# print(lRochelle.shape)\n",
    "lRochelle = lRochelle.query('destination_partner_balance_supp_1789==\"Etranger\"') #Pas la France\n",
    "lRochelle = lRochelle.query('destination_uhgs_id!=\"C0000009\"') #Afrique\n",
    "lRochelle = lRochelle.query('destination_uhgs_id!=\"A0146289\"') #Islande\n",
    "lRochelle = lRochelle.query('destination_uhgs_id!=\"B0000715\"')  #Terre-Neuve\n",
    "lRochelle = lRochelle.query('commodity_purpose!=\"Lège\"')  #pas à vide (Lège)\n",
    "lRochelle = lRochelle.query('commodity_purpose!=\"lest\"')  #pas à vide (lest)\n",
    "lRochelle = lRochelle.query('commodity_purpose2!=\"lest\"')  #pas à vide (lest)\n",
    "lRochelle = lRochelle.query('commodity_purpose!=\"pêche\"')  #pas pour la pêche\n",
    "print(lRochelle.shape) #(35, 17)\n",
    "\n",
    "\n",
    "#print(lRochelle.columns)\n",
    "\n",
    "#dunkerque = dunkerque.query('destination_state_1789_fr!=\"Grande-Bretagne\"') #Pas le smogglage vers l'angleterre\n",
    "\n",
    "lRochelle = lRochelle.drop(['Unnamed: 0'], axis=1) #'all_cargos'\n",
    "print(lRochelle.shape) #(35, 16)\n",
    "\n",
    "#Il arrive que des cargos soient na \n",
    "\n",
    "produits_connus = lRochelle.dropna(subset=['all_cargos'])\n",
    "print(\"Nombre de départs avec produits connus\")\n",
    "print(produits_connus.shape) #(35, 16)\n",
    "\n",
    "values = {\"all_cargos\": '', \"nb_cargo\": 0}\n",
    "lRochelle = lRochelle.fillna(value=values)\n",
    "\n",
    "\n",
    "## Maintenant on duplique les lignes : une par produit, et on aligne avec les produits de Toflit'18\n",
    "\n",
    "by_pointcalls =  unstack_cargos_in_pointcalls(lRochelle)\n",
    "export_lRochelle_1789 = pd.DataFrame(by_pointcalls, columns=['cargo', 'cargo_standardized_fr']+lRochelle.columns.tolist())\n",
    "\n",
    "#print(export_lRochelle_1789.columns)\n",
    "\n",
    "export_lRochelle_1789['commodity_as_toflit'] = export_lRochelle_1789['cargo_standardized_fr'].apply(translate_as_toflit_product)\n",
    "export_lRochelle_1789 = export_lRochelle_1789.drop(['commodity_purpose', 'commodity_purpose2', 'commodity_purpose3', 'commodity_purpose4', 'all_cargos'], axis=1)\n",
    "\n",
    "print(export_lRochelle_1789.columns)\n",
    "print(export_lRochelle_1789.shape) #(35, 14)\n",
    "\n",
    "export_lRochelle_1789.to_csv (r'./suite_flux_lRochelle_1789.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  destination_partner_balance_1789  count     sum        mean\n",
      "0                       Angleterre      6  1048.0  174.666667\n",
      "1                         Danemark      1   150.0  150.000000\n",
      "2              Etats de l'Empereur      8   512.0   64.000000\n",
      "3                       Etats-Unis      1   160.0  160.000000\n",
      "4                         Hollande      5   550.0  110.000000\n",
      "5                           Prusse      3   370.0  123.333333\n",
      "6       Quatre villes hanséatiques     10  1050.0  105.000000\n"
     ]
    }
   ],
   "source": [
    "## Agréger La Rochelle 1789 par partenaire\n",
    "\n",
    "import pandas as pd\n",
    "import pandas.core.frame as pf\n",
    "\n",
    "# Lire le fichier \n",
    "#export_lRochelle_1789 = pd.read_csv(\"./suite_flux_lRochelle_1789.csv\")\n",
    "\n",
    "# Dans ce cas, avec des produits jamais renseignés, on a nb_cargo = 0, et tonnage_per_product n'a pas de sens\n",
    "#export_lRochelle_1789['tonnage_per_product'] = export_lRochelle_1789['tonnage'] / export_lRochelle_1789['nb_cargo']\n",
    "#Diviser par 0 donne Infinity, donc on ne garde pas cette variable\n",
    "\n",
    "exports = pd.DataFrame(export_lRochelle_1789.groupby([ \"destination_partner_balance_1789\"])['tonnage'].agg(['count','sum', 'mean'])).reset_index()\n",
    "print(exports)\n",
    "\n",
    "#exports = pd.DataFrame(export_lRochelle_1789.groupby([ \"destination_partner_balance_1789\"])['tonnage','tonnage_per_product'].agg(['count', 'sum'])).reset_index()\n",
    "exports.set_axis(['destination_partner_balance_1789', 'nb_ships', 'sum_tonnage', 'tonnage moyen'], axis=1, inplace=True)\n",
    "exports.to_csv (r'./suite_export_laRochelle_1789_par_pays_par_produits.csv', index = None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La Rochelle _ 1787 \n",
    "Est-ce que là aussi les produits sont absents ? OUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'departure_uhgs_id', 'departure_fr',\n",
      "       'destination_uhgs_id', 'destination_fr',\n",
      "       'destination_partner_balance_1789',\n",
      "       'destination_partner_balance_supp_1789', 'destination_substate_1789_fr',\n",
      "       'destination_state_1789_fr', 'tonnage', 'outdate_fixed',\n",
      "       'commodity_purpose', 'commodity_purpose2', 'commodity_purpose3',\n",
      "       'commodity_purpose4', 'all_cargos', 'nb_cargo'],\n",
      "      dtype='object')\n",
      "(37, 17)\n",
      "(37, 16)\n",
      "Nombre de départs avec produits connus\n",
      "(0, 16)\n",
      "Index(['cargo', 'cargo_standardized_fr', 'departure_uhgs_id', 'departure_fr',\n",
      "       'destination_uhgs_id', 'destination_fr',\n",
      "       'destination_partner_balance_1789',\n",
      "       'destination_partner_balance_supp_1789', 'destination_substate_1789_fr',\n",
      "       'destination_state_1789_fr', 'tonnage', 'outdate_fixed', 'nb_cargo',\n",
      "       'commodity_as_toflit'],\n",
      "      dtype='object')\n",
      "(37, 14)\n"
     ]
    }
   ],
   "source": [
    "# Prendre les données\n",
    "##departure_ferme_bureau, departure_action \n",
    "#departure_ferme_bureau='La Rochelle'\n",
    "#Equivalent à ces ports\n",
    "#    Esnandes\n",
    "#    La Rochelle\n",
    "#    mer des Pertuis\n",
    "\n",
    "#http://data.portic.fr/api/rawflows/?format=csv&date=1787&params=departure_uhgs_id,departure_fr,destination_uhgs_id,destination_fr,destination_partner_balance_1789,destination_partner_balance_supp_1789,destination_substate_1789_fr,destination_state_1789_fr,tonnage,outdate_fixed,commodity_purpose,commodity_purpose2,commodity_purpose3,commodity_purpose4,all_cargos,nb_cargo\n",
    "\n",
    "#curl -o ./raw_flows_1789.csv \"data.portic.fr/api/rawflows/?format=csv&date=1787&params=departure_uhgs_id,departure_fr,destination_uhgs_id,destination_fr,destination_partner_balance_1789,destination_partner_balance_supp_1789,destination_substate_1789_fr,destination_state_1789_fr,tonnage,outdate_fixed,commodity_purpose,commodity_purpose2,commodity_purpose3,commodity_purpose4,all_cargos,nb_cargo\"\n",
    "raw_flows = pd.read_csv(\"./raw_flows_1787.csv\", encoding='utf8', sep=',')\n",
    "\n",
    "\n",
    "print(raw_flows.columns)\n",
    "\n",
    "#Filtrer : oui, la pêche et le lest et ce qui part vers la France \n",
    "# Mais tagger les valeurs expédiées en GB particulièrement ? Oui. \n",
    "\n",
    "lRochelle = raw_flows.query('departure_fr==\"La Rochelle\" or departure_fr==\"Esnandes\" or departure_fr==\"mer des Pertuis\"')\n",
    "# print(lRochelle.shape)\n",
    "lRochelle = lRochelle.query('destination_partner_balance_supp_1789==\"Etranger\"') #Pas la France\n",
    "lRochelle = lRochelle.query('destination_uhgs_id!=\"C0000009\"') #Afrique\n",
    "lRochelle = lRochelle.query('destination_uhgs_id!=\"A0146289\"') #Islande\n",
    "lRochelle = lRochelle.query('destination_uhgs_id!=\"B0000715\"')  #Terre-Neuve\n",
    "lRochelle = lRochelle.query('commodity_purpose!=\"Lège\"')  #pas à vide (Lège)\n",
    "lRochelle = lRochelle.query('commodity_purpose!=\"lest\"')  #pas à vide (lest)\n",
    "lRochelle = lRochelle.query('commodity_purpose2!=\"lest\"')  #pas à vide (lest)\n",
    "lRochelle = lRochelle.query('commodity_purpose!=\"pêche\"')  #pas pour la pêche\n",
    "print(lRochelle.shape) #(37, 17)\n",
    "\n",
    "\n",
    "#print(lRochelle.columns)\n",
    "\n",
    "#dunkerque = dunkerque.query('destination_state_1789_fr!=\"Grande-Bretagne\"') #Pas le smogglage vers l'angleterre\n",
    "\n",
    "lRochelle = lRochelle.drop(['Unnamed: 0'], axis=1) #'all_cargos'\n",
    "print(lRochelle.shape) #(37, 16)\n",
    "\n",
    "#Il arrive que des cargos soient na \n",
    "\n",
    "produits_connus = lRochelle.dropna(subset=['all_cargos'])\n",
    "print(\"Nombre de départs avec produits connus\")\n",
    "print(produits_connus.shape) #(37, 16)\n",
    "\n",
    "values = {\"all_cargos\": '', \"nb_cargo\": 0}\n",
    "lRochelle = lRochelle.fillna(value=values)\n",
    "\n",
    "\n",
    "## Maintenant on duplique les lignes : une par produit, et on aligne avec les produits de Toflit'18\n",
    "\n",
    "by_pointcalls =  unstack_cargos_in_pointcalls(lRochelle)\n",
    "export_lRochelle_1787 = pd.DataFrame(by_pointcalls, columns=['cargo', 'cargo_standardized_fr']+lRochelle.columns.tolist())\n",
    "\n",
    "#print(export_lRochelle_1787.columns)\n",
    "\n",
    "export_lRochelle_1787['commodity_as_toflit'] = export_lRochelle_1787['cargo_standardized_fr'].apply(translate_as_toflit_product)\n",
    "export_lRochelle_1787 = export_lRochelle_1787.drop(['commodity_purpose', 'commodity_purpose2', 'commodity_purpose3', 'commodity_purpose4', 'all_cargos'], axis=1)\n",
    "\n",
    "print(export_lRochelle_1787.columns)\n",
    "print(export_lRochelle_1787.shape) #(37, 14)\n",
    "\n",
    "export_lRochelle_1787.to_csv (r'./suite_flux_lRochelle_1787.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  destination_partner_balance_1789  count     sum        mean\n",
      "0                       Angleterre      4   770.0  192.500000\n",
      "1                         Danemark      3   360.0  120.000000\n",
      "2                          Espagne      3   230.0   76.666667\n",
      "3              Etats de l'Empereur      9   996.0  110.666667\n",
      "4                         Hollande      4   490.0  122.500000\n",
      "5                         Portugal      2   214.0  107.000000\n",
      "6       Quatre villes hanséatiques     12  1324.0  110.333333\n"
     ]
    }
   ],
   "source": [
    "# agréger par produit, partenaire toflit (qui peut le plus peu le moins)\n",
    "\n",
    "## Agréger La Rochelle 1789 par partenaire\n",
    "# Dans ce cas, avec des produits jamais renseignés, on a nb_cargo = 0, et tonnage_per_product n'a pas de sens\n",
    "\n",
    "import pandas as pd\n",
    "import pandas.core.frame as pf\n",
    "\n",
    "# Lire le fichier \n",
    "#export_lRochelle_1787 = pd.read_csv(\"./suite_flux_lRochelle_1787.csv\")\n",
    "\n",
    "exports = pd.DataFrame(export_lRochelle_1787.groupby([ \"destination_partner_balance_1789\"])['tonnage'].agg(['count','sum', 'mean'])).reset_index()\n",
    "print(exports)\n",
    "\n",
    "exports.set_axis(['destination_partner_balance_1789', 'nb_ships', 'sum_tonnage', 'tonnage moyen'], axis=1, inplace=True)\n",
    "exports.to_csv (r'./suite_export_laRochelle_1787_par_pays_par_produits.csv', index = None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marseille, 1789\n",
    "Il y aura plusieurs sources. Et le petit cabotage sort parfois en doublon du G5 (net_route_marker = Q)\n",
    "Expéditions \"coloniales\" Marseille (1789)\n",
    "G5\n",
    "Registre du petit cabotage (1786-1787)\n",
    "Santé Marseille\n",
    "\n",
    "Une petit préanalayse en SQL m'a montré que la requête ne me sort pas de doublon (departure_ferme_bureau='Marseille' and destination_partner_balance_supp_1789='Etranger') parce que je controle le net_route_marker des raw_flows à la destination.\n",
    "Bref, seule l'analyse 1789 ramène une cinquantaine de lignes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'departure_uhgs_id', 'departure_fr',\n",
      "       'destination_uhgs_id', 'destination_fr',\n",
      "       'destination_partner_balance_1789',\n",
      "       'destination_partner_balance_supp_1789', 'destination_substate_1789_fr',\n",
      "       'destination_state_1789_fr', 'tonnage', 'outdate_fixed',\n",
      "       'commodity_purpose', 'commodity_purpose2', 'commodity_purpose3',\n",
      "       'commodity_purpose4', 'all_cargos', 'nb_cargo'],\n",
      "      dtype='object')\n",
      "(42, 17)\n",
      "Nombre de départs avec produits connus\n",
      "(42, 16)\n",
      "Index(['cargo', 'cargo_standardized_fr', 'departure_uhgs_id', 'departure_fr',\n",
      "       'destination_uhgs_id', 'destination_fr',\n",
      "       'destination_partner_balance_1789',\n",
      "       'destination_partner_balance_supp_1789', 'destination_substate_1789_fr',\n",
      "       'destination_state_1789_fr', 'tonnage', 'outdate_fixed', 'nb_cargo',\n",
      "       'commodity_as_toflit'],\n",
      "      dtype='object')\n",
      "(238, 14)\n"
     ]
    }
   ],
   "source": [
    "# Prendre les données\n",
    "#departure_ferme_bureau='Marseille'\n",
    "#Equivalent à ces ports\n",
    "#    Frioul\n",
    "#    Marseille\n",
    "\n",
    "#http://data.portic.fr/api/rawflows/?format=csv&date=1789&params=departure_uhgs_id,departure_fr,destination_uhgs_id,destination_fr,destination_partner_balance_1789,destination_partner_balance_supp_1789,destination_substate_1789_fr,destination_state_1789_fr,tonnage,outdate_fixed,commodity_purpose,commodity_purpose2,commodity_purpose3,commodity_purpose4,all_cargos,nb_cargo\n",
    "\n",
    "#curl -o ./raw_flows_1789.csv \"data.portic.fr/api/rawflows/?format=csv&date=1789&params=departure_uhgs_id,departure_fr,destination_uhgs_id,destination_fr,destination_partner_balance_1789,destination_partner_balance_supp_1789,destination_substate_1789_fr,destination_state_1789_fr,tonnage,outdate_fixed,commodity_purpose,commodity_purpose2,commodity_purpose3,commodity_purpose4,all_cargos,nb_cargo\"\n",
    "raw_flows = pd.read_csv(\"./raw_flows_1789.csv\", encoding='utf8', sep=',')\n",
    "\n",
    "\n",
    "print(raw_flows.columns)\n",
    "\n",
    "#Filtrer : oui, la pêche et le lest et ce qui part vers la France \n",
    "# Mais tagger les valeurs expédiées en GB particulièrement ? Oui. \n",
    "\n",
    "Marseille_1789 = raw_flows.query('departure_fr==\"Marseille\" or departure_fr==\"Frioul\"')\n",
    "# print(lRochelle.shape)\n",
    "Marseille_1789 = Marseille_1789.query('destination_partner_balance_supp_1789==\"Etranger\"') #Pas la France\n",
    "Marseille_1789 = Marseille_1789.query('destination_uhgs_id!=\"C0000009\"') #Afrique\n",
    "Marseille_1789 = Marseille_1789.query('destination_uhgs_id!=\"A0146289\"') #Islande\n",
    "Marseille_1789 = Marseille_1789.query('destination_uhgs_id!=\"B0000715\"')  #Terre-Neuve\n",
    "Marseille_1789 = Marseille_1789.query('commodity_purpose!=\"Lège\"')  #pas à vide (Lège)\n",
    "Marseille_1789 = Marseille_1789.query('commodity_purpose!=\"lest\"')  #pas à vide (lest)\n",
    "Marseille_1789 = Marseille_1789.query('commodity_purpose2!=\"lest\"')  #pas à vide (lest)\n",
    "Marseille_1789 = Marseille_1789.query('commodity_purpose!=\"pêche\"')  #pas pour la pêche\n",
    "print(Marseille_1789.shape) #(42, 17)\n",
    "\n",
    "\n",
    "#dunkerque = dunkerque.query('destination_state_1789_fr!=\"Grande-Bretagne\"') #Pas le smogglage vers l'angleterre\n",
    "\n",
    "Marseille_1789 = Marseille_1789.drop(['Unnamed: 0'], axis=1) #'all_cargos'\n",
    "\n",
    "#Il arrive que des cargos soient na \n",
    "\n",
    "produits_connus = Marseille_1789.dropna(subset=['all_cargos'])\n",
    "print(\"Nombre de départs avec produits connus\")\n",
    "print(produits_connus.shape) #(42, 16)\n",
    "\n",
    "values = {\"all_cargos\": '', \"nb_cargo\": 0}\n",
    "Marseille_1789 = Marseille_1789.fillna(value=values)\n",
    "\n",
    "\n",
    "## Maintenant on duplique les lignes : une par produit, et on aligne avec les produits de Toflit'18\n",
    "\n",
    "by_pointcalls =  unstack_cargos_in_pointcalls(Marseille_1789)\n",
    "export_Marseille_1789 = pd.DataFrame(by_pointcalls, columns=['cargo', 'cargo_standardized_fr']+Marseille_1789.columns.tolist())\n",
    "\n",
    "\n",
    "export_Marseille_1789['commodity_as_toflit'] = export_Marseille_1789['cargo_standardized_fr'].apply(translate_as_toflit_product)\n",
    "export_Marseille_1789 = export_Marseille_1789.drop(['commodity_purpose', 'commodity_purpose2', 'commodity_purpose3', 'commodity_purpose4', 'all_cargos'], axis=1)\n",
    "\n",
    "print(export_Marseille_1789.columns)\n",
    "print(export_Marseille_1789.shape) #(238, 14)\n",
    "\n",
    "export_Marseille_1789.to_csv (r'./suite_flux_Marseille_1789.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   destination_partner_balance_1789     commodity_as_toflit  count\n",
      "0                           Espagne      Unknown for TOFLIT      1\n",
      "1                           Espagne                    bois      1\n",
      "2                           Espagne  bois pour construction      2\n",
      "3                           Espagne                 cercles      1\n",
      "4                           Espagne             chair salée      1\n",
      "..                              ...                     ...    ...\n",
      "59                         Portugal                   savon      2\n",
      "60                         Portugal                souliers      1\n",
      "61                         Portugal           toile à voile      1\n",
      "62                         Portugal                verrerie      2\n",
      "63                         Portugal                     vin      3\n",
      "\n",
      "[64 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cplume01\\AppData\\Local\\Temp\\ipykernel_15796\\4131446049.py:16: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  exports = pd.DataFrame(export_Marseille_1789.groupby([ \"destination_partner_balance_1789\",\"commodity_as_toflit\"])['tonnage','tonnage_per_product'].agg(['count', 'sum'])).reset_index()\n"
     ]
    }
   ],
   "source": [
    "## Agréger à Marseille 1789\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import pandas.core.frame as pf\n",
    "\n",
    "# Lire le fichier \n",
    "#export_Marseille_1789 = pd.read_csv(\"./suite_flux_dunkerque_1789.csv\")\n",
    "export_Marseille_1789['tonnage_per_product'] = export_Marseille_1789['tonnage'] / export_Marseille_1789['nb_cargo']\n",
    "\n",
    "gdata = pf.DataFrame({'count' : export_Marseille_1789.groupby( [ \"destination_partner_balance_1789\",\"commodity_as_toflit\"] ).size()}).reset_index()\n",
    "print(gdata)\n",
    "\n",
    "pd.DataFrame(export_Marseille_1789.groupby([ \"destination_partner_balance_1789\",\"commodity_as_toflit\"])['tonnage'].agg(['sum','count', 'mean'])).reset_index()\n",
    "\n",
    "exports = pd.DataFrame(export_Marseille_1789.groupby([ \"destination_partner_balance_1789\",\"commodity_as_toflit\"])['tonnage','tonnage_per_product'].agg(['count', 'sum'])).reset_index()\n",
    "exports.set_axis(['destination_partner_balance_1789', 'commodity_as_toflit', 'nb_ships', 'sum_tonnage', 'nb_ships2', 'sum_tonnage_per_product'], axis=1, inplace=True)\n",
    "exports.to_csv (r'./suite_export_marseille_1789_par_pays_par_produits.csv', index = None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Christine Plumejeaud-Perreau, UMR MIGRINTER 7301\n",
    "03 mai 2022\n",
    "projet ANR PORTIC\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec890f973dd9e3cac31a738b8560dfcf5ac073d4c5ea92d19b6fe0e1e1d90d79"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('dunkerque22': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
